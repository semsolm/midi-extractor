"""
ë“œëŸ¼ íƒ€ê²© ê²€ì¶œ ë°ì´í„° ë¡œë” (í”¼ë“œë°± ë°˜ì˜ ìµœì¢… ë²„ì „)

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. âœ… Â±1 í”„ë ˆì„ í™•ì¥ ë¼ë²¨ (onset spread)
2. âœ… SpecAugment ì¶”ê°€ (time_mask_param ì¶•ì†Œ: 30â†’10)
3. âœ… Silent sample augmentation (10%â†’15%)
4. âœ… Mel normalization ì¶”ê°€ (mean/std)
5. âœ… í´ë˜ìŠ¤ë³„ threshold íƒìƒ‰ ì§€ì›
"""

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
import librosa
import pretty_midi
from pathlib import Path
from typing import Tuple


# ============================================
# MIDI ë“œëŸ¼ ë…¸íŠ¸ ë§¤í•‘
# ============================================
DRUM_MAPPING = {
    'kick': [36],
    'snare': [38, 40],
    'hihat': [
        42, 44, 46,     # í•˜ì´í–‡ ê¸°ë³¸ 3ì¢…
        49, 57,         # í¬ë˜ì‰¬ 1, í¬ë˜ì‰¬ 2
        51, 59,         # ë¼ì´ë“œ 1, ë¼ì´ë“œ 2
        52, 55,         # ì°¨ì´ë‚˜, ìŠ¤í”Œë˜ì‹œ
        53              # ë¼ì´ë“œ ë²¨
    ]
}


# ============================================
# ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ ì„¤ì •
# ============================================
MAX_SEQ_LEN = 2500


class DrumDatasetConfig:
    """ë°ì´í„°ì…‹ ì„¤ì • (í”¼ë“œë°± ë°˜ì˜ ìµœì¢… ë²„ì „)"""
    def __init__(self):
        # ê²½ë¡œ ì„¤ì •
        self.csv_path = r"D:\model_test\e-gmd-v1.0.0\e-gmd-v1.0.0.csv"
        self.data_root = r"D:\model_test\e-gmd-v1.0.0"

        # ì‚¬ì „ ê³„ì‚° ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        self.use_precomputed = True
        self.precomputed_root = "./precomputed_bigru_data_hop256_final"

        # í•„í„°ë§ ì„¤ì •
        self.exclude_styles = ['jazz']
        self.min_duration = 10.0

        # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì„¤ì •
        self.sample_rate = 22050
        self.n_fft = 2048
        self.hop_length = 256
        self.n_mels = 128
        self.fmin = 20
        self.fmax = 8000

        # ë°ì´í„° ì¦ê°• ì„¤ì •
        self.use_augmentation = True
        self.augment_prob = 0.5

        # SpecAugment ì„¤ì • (ê°œì„ : time_mask_param ì¶•ì†Œ)
        self.use_spec_augment = True
        self.freq_mask_param = 12  # 15 â†’ 12
        self.time_mask_param = 10  # 30 â†’ 10 (onset ë³´ì¡´)
        self.n_freq_masks = 2
        self.n_time_masks = 2

        # Silent sample ì¦ê°• (ê°œì„ : 10% â†’ 15%)
        self.add_silent_prob = 0.15  # 0.1 â†’ 0.15

        # Mel normalization ì¶”ê°€
        self.use_mel_normalization = True

        # ë ˆì´ë¸” ì„¤ì •
        self.drum_types = ['kick', 'snare', 'hihat']
        self.n_classes = len(self.drum_types)

        # Â±1 í”„ë ˆì„ í™•ì¥ ì„¤ì •
        self.label_spread_frames = 1

        # ì‹œê°„ í•´ìƒë„
        self.frame_duration = self.hop_length / self.sample_rate

        # ì‹œí€€ìŠ¤ ê¸¸ì´ ì œí•œ
        self.max_seq_len = MAX_SEQ_LEN


def load_metadata(config: DrumDatasetConfig) -> pd.DataFrame:
    """CSV ë©”íƒ€ë°ì´í„° ë¡œë”© ë° í•„í„°ë§"""
    df = pd.read_csv(config.csv_path)
    df = df[~df['style'].str.contains('jazz', case=False, na=False)]
    df = df[df['duration'] > config.min_duration]
    return df


def augment_audio(y: np.ndarray, sr: int) -> np.ndarray:
    """
    ê°„ë‹¨í•œ ì˜¤ë””ì˜¤ ì¦ê°•
    â€» Gainë§Œ ì ìš© (onset alignment ë³´ì¡´)
    """
    # Gain adjustment
    if np.random.rand() < 0.5:
        gain_db = np.random.uniform(-6, 6)
        y = y * (10 ** (gain_db / 20))

    # Clipping ë°©ì§€
    y = np.clip(y, -1.0, 1.0)

    return y


def spec_augment(mel_spec: np.ndarray, config: DrumDatasetConfig) -> np.ndarray:
    """
    SpecAugment ì ìš©: Frequency/Time Masking

    ê°œì„ : time_mask_paramì„ ì¤„ì—¬ì„œ onset ë³´ì¡´
    """
    mel_spec = mel_spec.copy()
    T, F = mel_spec.shape

    # Frequency Masking
    for _ in range(config.n_freq_masks):
        f = np.random.randint(0, min(config.freq_mask_param, F))
        if f > 0:
            f0 = np.random.randint(0, F - f)
            mel_spec[:, f0:f0+f] = 0

    # Time Masking (onset ë³´ì¡´ì„ ìœ„í•´ ì¶•ì†Œ)
    for _ in range(config.n_time_masks):
        t = np.random.randint(0, min(config.time_mask_param, T))
        if t > 0:
            t0 = np.random.randint(0, max(1, T - t))
            mel_spec[t0:t0+t, :] = 0

    return mel_spec


def normalize_mel(mel_spec: np.ndarray) -> np.ndarray:
    """
    ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì •ê·œí™” (mean/std)

    ê°œì„ : ë…¹ìŒ ì„¸ê¸°ì— ë”°ë¥¸ dynamic range ë³€ë™ ì™„í™”
    """
    mean = np.mean(mel_spec)
    std = np.std(mel_spec)

    if std > 1e-5:
        mel_spec = (mel_spec - mean) / std

    return mel_spec


def wav_to_melspectrogram(wav_path: str, config: DrumDatasetConfig, augment: bool = False) -> np.ndarray:
    """WAV íŒŒì¼ì„ ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜"""
    y, sr = librosa.load(wav_path, sr=config.sample_rate, mono=True)

    # ë°ì´í„° ì¦ê°• ì ìš© (training ì‹œì—ë§Œ)
    if augment and config.use_augmentation and np.random.rand() < config.augment_prob:
        y = augment_audio(y, sr)

    mel_spec = librosa.feature.melspectrogram(
        y=y, sr=sr, n_fft=config.n_fft, hop_length=config.hop_length,
        n_mels=config.n_mels, fmin=config.fmin, fmax=config.fmax
    )

    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    mel_spec_db = mel_spec_db.T

    # ì •ê·œí™” ì ìš© (ê°œì„ )
    if config.use_mel_normalization:
        mel_spec_db = normalize_mel(mel_spec_db)

    return mel_spec_db


def midi_to_labels(midi_path: str, n_frames: int, config: DrumDatasetConfig) -> np.ndarray:
    """
    MIDI íŒŒì¼ì„ í”„ë ˆì„ë³„ ë©€í‹°ë ˆì´ë¸”ë¡œ ë³€í™˜ (Â±1 í”„ë ˆì„ í™•ì¥)
    """
    midi_data = pretty_midi.PrettyMIDI(midi_path)
    labels = np.zeros((n_frames, config.n_classes), dtype=np.float32)

    for instrument in midi_data.instruments:
        if instrument.is_drum:
            for note in instrument.notes:
                onset_time = note.start
                frame_idx = int(onset_time / config.frame_duration)

                if 0 <= frame_idx < n_frames:
                    for drum_idx, (drum_type, note_numbers) in enumerate(DRUM_MAPPING.items()):
                        if note.pitch in note_numbers:
                            # Â±1 í”„ë ˆì„ í™•ì¥
                            for offset in range(-config.label_spread_frames,
                                              config.label_spread_frames + 1):
                                target_frame = frame_idx + offset
                                if 0 <= target_frame < n_frames:
                                    labels[target_frame, drum_idx] = 1.0
                            break

    return labels


# ============================================
# ì¼ë°˜ Dataset (ì‹¤ì‹œê°„ ë³€í™˜)
# ============================================
class DrumDataset(Dataset):
    """PyTorch Dataset for Drum Onset Detection (í”¼ë“œë°± ë°˜ì˜ ìµœì¢… ë²„ì „)"""

    def __init__(self, metadata: pd.DataFrame, config: DrumDatasetConfig, split: str = 'train'):
        self.config = config
        self.split = split
        self.data = metadata[metadata['split'] == split].reset_index(drop=True)
        self.is_training = (split == 'train')

    def __len__(self):
        # Silent sample ì¶”ê°€ ê³ ë ¤ (15%ë¡œ ì¦ê°€)
        base_len = len(self.data)
        if self.is_training and self.config.add_silent_prob > 0:
            silent_samples = int(base_len * self.config.add_silent_prob / (1 - self.config.add_silent_prob))
            return base_len + silent_samples
        return base_len

    def __getitem__(self, idx):
        base_len = len(self.data)

        # Silent sample ìƒì„± (training ì‹œì—ë§Œ)
        if self.is_training and idx >= base_len:
            # ë¬´ìŒ ìƒ˜í”Œ ìƒì„±
            seq_len = np.random.randint(500, 1500)
            mel_spec = torch.zeros(seq_len, self.config.n_mels, dtype=torch.float32)
            labels = torch.zeros(seq_len, self.config.n_classes, dtype=torch.float32)
            return mel_spec, labels

        # ì¼ë°˜ ë°ì´í„° ë¡œë”©
        row = self.data.iloc[idx % base_len]
        wav_filename = row['audio_filename']
        midi_filename = row['midi_filename']

        wav_path = os.path.join(self.config.data_root, wav_filename)
        midi_path = os.path.join(self.config.data_root, midi_filename)

        # WAV â†’ Mel ë³€í™˜ (training ì‹œ augmentation ì ìš©)
        mel_spec = wav_to_melspectrogram(wav_path, self.config, augment=self.is_training)

        # SpecAugment ì ìš© (training ì‹œì—ë§Œ)
        if self.is_training and self.config.use_spec_augment and np.random.rand() < 0.5:
            mel_spec = spec_augment(mel_spec, self.config)

        n_frames = mel_spec.shape[0]
        labels = midi_to_labels(midi_path, n_frames, self.config)

        mel_spec = torch.FloatTensor(mel_spec)
        labels = torch.FloatTensor(labels)

        return mel_spec, labels


# ============================================
# ì‚¬ì „ ê³„ì‚° Dataset
# ============================================
class PrecomputedDrumDataset(Dataset):
    """ì‚¬ì „ ê³„ì‚°ëœ .npy íŒŒì¼ì„ ë¡œë”©í•˜ëŠ” ì´ˆê³ ì† Dataset (í”¼ë“œë°± ë°˜ì˜ ìµœì¢… ë²„ì „)"""

    def __init__(self, metadata: pd.DataFrame, config: DrumDatasetConfig, split: str = 'train'):
        self.config = config
        self.split = split
        self.root = config.precomputed_root
        self.data = metadata[metadata['split'] == split].reset_index(drop=True)
        self.is_training = (split == 'train')

        # íŒŒì¼ ê²½ë¡œ ë¯¸ë¦¬ êµ¬ì„±
        self.mel_paths = []
        self.label_paths = []

        for _, row in self.data.iterrows():
            fname = row['audio_filename']
            fname = fname.replace('/', '_').replace('\\', '_').replace('.wav', '')

            mel_path = os.path.join(self.root, split, 'mel', f"{fname}.npy")
            label_path = os.path.join(self.root, split, 'label', f"{fname}.npy")

            self.mel_paths.append(mel_path)
            self.label_paths.append(label_path)

    def __len__(self):
        base_len = len(self.data)
        if self.is_training and self.config.add_silent_prob > 0:
            silent_samples = int(base_len * self.config.add_silent_prob / (1 - self.config.add_silent_prob))
            return base_len + silent_samples
        return base_len

    def __getitem__(self, idx):
        base_len = len(self.data)

        # Silent sample ìƒì„±
        if self.is_training and idx >= base_len:
            seq_len = np.random.randint(500, 1500)
            mel_spec = torch.zeros(seq_len, self.config.n_mels, dtype=torch.float32)
            labels = torch.zeros(seq_len, self.config.n_classes, dtype=torch.float32)
            return mel_spec, labels

        # ì¼ë°˜ ë°ì´í„° ë¡œë”©
        mel_spec = np.load(self.mel_paths[idx % base_len])
        labels = np.load(self.label_paths[idx % base_len])

        # SpecAugment ì ìš© (training ì‹œì—ë§Œ)
        if self.is_training and self.config.use_spec_augment and np.random.rand() < 0.5:
            mel_spec = spec_augment(mel_spec, self.config)

        mel_spec = torch.FloatTensor(mel_spec)
        labels = torch.FloatTensor(labels)

        return mel_spec, labels


# ============================================
# Collate Function (ë©”ëª¨ë¦¬ ìµœì í™”)
# ============================================
def collate_fn_train(batch):
    """Trainingìš© collate function - ëœë¤ í¬ë¡­"""
    clipped_batch = []

    for mel, label in batch:
        seq_len = mel.shape[0]

        if seq_len > MAX_SEQ_LEN:
            start = np.random.randint(0, seq_len - MAX_SEQ_LEN + 1)
            mel = mel[start:start + MAX_SEQ_LEN]
            label = label[start:start + MAX_SEQ_LEN]

        clipped_batch.append((mel, label))

    # ë°°ì¹˜ íŒ¨ë”©
    lengths = [mel.shape[0] for mel, _ in clipped_batch]
    max_len = max(lengths)

    batch_size = len(clipped_batch)
    n_mels = clipped_batch[0][0].shape[1]
    n_classes = clipped_batch[0][1].shape[1]

    mel_specs = torch.zeros(batch_size, max_len, n_mels)
    label_batch = torch.zeros(batch_size, max_len, n_classes)

    for i, (mel, label) in enumerate(clipped_batch):
        length = mel.shape[0]
        mel_specs[i, :length, :] = mel
        label_batch[i, :length, :] = label

    lengths = torch.LongTensor(lengths)

    return mel_specs, label_batch, lengths


def collate_fn_eval(batch):
    """Validation/Testìš© collate function - deterministic"""
    clipped_batch = []

    for mel, label in batch:
        seq_len = mel.shape[0]

        if seq_len > MAX_SEQ_LEN:
            mel = mel[:MAX_SEQ_LEN]
            label = label[:MAX_SEQ_LEN]

        clipped_batch.append((mel, label))

    # ë°°ì¹˜ íŒ¨ë”©
    lengths = [mel.shape[0] for mel, _ in clipped_batch]
    max_len = max(lengths)

    batch_size = len(clipped_batch)
    n_mels = clipped_batch[0][0].shape[1]
    n_classes = clipped_batch[0][1].shape[1]

    mel_specs = torch.zeros(batch_size, max_len, n_mels)
    label_batch = torch.zeros(batch_size, max_len, n_classes)

    for i, (mel, label) in enumerate(clipped_batch):
        length = mel.shape[0]
        mel_specs[i, :length, :] = mel
        label_batch[i, :length, :] = label

    lengths = torch.LongTensor(lengths)

    return mel_specs, label_batch, lengths


# ============================================
# DataLoader ìƒì„± í•¨ìˆ˜ë“¤
# ============================================
def get_precomputed_dataloaders(
    config: DrumDatasetConfig,
    batch_size: int = 16,
    num_workers: int = 8
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """ì‚¬ì „ ê³„ì‚°ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ˆê³ ì† DataLoader ìƒì„±"""
    print("=" * 80)
    print("ğŸš€ ì´ˆê³ ì† DataLoader ìƒì„± (ì‚¬ì „ ê³„ì‚° ë°ì´í„° ì‚¬ìš©)")
    print("=" * 80)
    print(f"ì‚¬ì „ ê³„ì‚° ë°ì´í„° ê²½ë¡œ: {config.precomputed_root}")
    print(f"Batch size: {batch_size}")
    print(f"Num workers: {num_workers}")
    print(f"Max sequence length: {MAX_SEQ_LEN} frames (~{MAX_SEQ_LEN * config.frame_duration:.1f}ì´ˆ)")
    print(f"Frame duration: {config.frame_duration*1000:.1f}ms (hop_length={config.hop_length})")
    print(f"Label spread: Â±{config.label_spread_frames} frames")
    print(f"SpecAugment: {config.use_spec_augment} (time_mask={config.time_mask_param})")
    print(f"Silent sample prob: {config.add_silent_prob}")
    print(f"Mel normalization: {config.use_mel_normalization}")
    print("=" * 80)

    if not os.path.exists(config.precomputed_root):
        raise FileNotFoundError(
            f"âŒ ì‚¬ì „ ê³„ì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {config.precomputed_root}\n"
            f"ë¨¼ì € npy_maker_final.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!"
        )

    metadata = load_metadata(config)

    train_dataset = PrecomputedDrumDataset(metadata, config, split='train')
    val_dataset = PrecomputedDrumDataset(metadata, config, split='validation')
    test_dataset = PrecomputedDrumDataset(metadata, config, split='test')

    print(f"\n[TRAIN] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(train_dataset)} ìƒ˜í”Œ (silent í¬í•¨)")
    print(f"[VAL] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(val_dataset)} íŒŒì¼")
    print(f"[TEST] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(test_dataset)} íŒŒì¼")

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn_train,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn_eval,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn_eval,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    print(f"\nâœ… ì´ˆê³ ì† DataLoader ìƒì„± ì™„ë£Œ")
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Val batches: {len(val_loader)}")
    print(f"   Test batches: {len(test_loader)}")

    return train_loader, val_loader, test_loader


def get_normal_dataloaders(
    config: DrumDatasetConfig,
    batch_size: int = 16,
    num_workers: int = 8
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """ì¼ë°˜ DataLoader ìƒì„± (ì‹¤ì‹œê°„ WAV â†’ Mel ë³€í™˜)"""
    print("=" * 80)
    print("ğŸ“‚ ì¼ë°˜ DataLoader ìƒì„± (ì‹¤ì‹œê°„ ë³€í™˜)")
    print("=" * 80)
    print(f"Batch size: {batch_size}")
    print(f"Num workers: {num_workers}")
    print(f"Max sequence length: {MAX_SEQ_LEN} frames (~{MAX_SEQ_LEN * config.frame_duration:.1f}ì´ˆ)")
    print(f"Frame duration: {config.frame_duration*1000:.1f}ms (hop_length={config.hop_length})")
    print(f"Data augmentation: {config.use_augmentation}")
    print(f"Label spread: Â±{config.label_spread_frames} frames")
    print(f"SpecAugment: {config.use_spec_augment} (time_mask={config.time_mask_param})")
    print(f"Silent sample prob: {config.add_silent_prob}")
    print(f"Mel normalization: {config.use_mel_normalization}")
    print("=" * 80)

    metadata = load_metadata(config)

    train_dataset = DrumDataset(metadata, config, split='train')
    val_dataset = DrumDataset(metadata, config, split='validation')
    test_dataset = DrumDataset(metadata, config, split='test')

    print(f"\n[TRAIN] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(train_dataset)} ìƒ˜í”Œ (silent í¬í•¨)")
    print(f"[VAL] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(val_dataset)} íŒŒì¼")
    print(f"[TEST] ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {len(test_dataset)} íŒŒì¼")

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn_train,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn_eval,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn_eval,
        pin_memory=True,
        persistent_workers=True if num_workers > 0 else False,
        prefetch_factor=2 if num_workers > 0 else None
    )

    print(f"\nâœ… ì¼ë°˜ DataLoader ìƒì„± ì™„ë£Œ")
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Val batches: {len(val_loader)}")
    print(f"   Test batches: {len(test_loader)}")

    return train_loader, val_loader, test_loader


# ============================================
# í†µí•© DataLoader ìƒì„± í•¨ìˆ˜
# ============================================
def get_dataloaders(
    config: DrumDatasetConfig,
    batch_size: int = 16,
    num_workers: int = 8
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """í†µí•© DataLoader ìƒì„± í•¨ìˆ˜"""
    if config.use_precomputed:
        return get_precomputed_dataloaders(config, batch_size, num_workers)
    else:
        return get_normal_dataloaders(config, batch_size, num_workers)


if __name__ == "__main__":
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    import time

    config = DrumDatasetConfig()

    print("\n" + "=" * 80)
    print("ğŸ§ª ë°ì´í„° ë¡œë”© ëª¨ë“œ í…ŒìŠ¤íŠ¸ (í”¼ë“œë°± ë°˜ì˜ ìµœì¢… ë²„ì „)")
    print("=" * 80)

    config.use_precomputed = False

    try:
        train_loader, val_loader, test_loader = get_dataloaders(
            config, batch_size=4, num_workers=2
        )

        print("\nâ±ï¸  ì†ë„ í…ŒìŠ¤íŠ¸ (5 ë°°ì¹˜)...")
        start = time.time()

        for i, (mel_specs, labels, lengths) in enumerate(train_loader):
            if i >= 5:
                break
            print(f"  Batch {i+1}: mel={mel_specs.shape}, label={labels.shape}, max_len={lengths.max()}")
            print(f"    Label density: {labels.sum(dim=(0,1)) / lengths.sum()}")
            print(f"    Mel stats: mean={mel_specs.mean():.3f}, std={mel_specs.std():.3f}")

        elapsed = time.time() - start
        print(f"\nâœ… 5 ë°°ì¹˜ ë¡œë”© ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"   ë°°ì¹˜ë‹¹ í‰ê· : {elapsed/5:.3f}ì´ˆ")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")